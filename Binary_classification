# mlp for binary classification
from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
# load the dataset
path = 'https://raw.githubusercontent.com/Eliasmarcet91/datasets/main/penguins_binary_classification.csv'

df = read_csv(path, header=1)


# drop the 'island' column
df.drop(columns=[df.columns[1]], inplace=True)
df.head()

# Split into input and output columns
X = df.values[:, 1:]
y = df.values[:, 0]

# Ensure all data are floating point values
X = X.astype('float32')

# encode strings to integer
encoder = LabelEncoder()
y = encoder.fit_transform(y)

mapping = dict(zip(encoder.classes_, range(len(encoder.classes_))))
print(mapping)

# split into train and test datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

# determine the number of input features
n_features = X_train.shape[1]

# define model
bi_model = Sequential()
bi_model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))
bi_model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))
bi_model.add(Dense(1, activation='sigmoid'))

# compile the model
bi_model.add.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# fit the model
bi_model.add.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)

# evaluate the model
loss, acc = bi_model.add.evaluate(X_test, y_test, verbose=0)
print('Test Accuracy: %.3f' % acc)

# Make a prediction
row = [39.5, 17.4, 186.0, 4575, 2009]
#row = [39.5, 17.4, 186.0, 3500, 2009]

# Reshape the input data to a 2D array
row = [row]

# Predict
yhat = model.predict(row)

# Access the predicted value
predicted_value = yhat[0][0]

# Print the predicted value
print('Predicted Penguin: %.1f' % predicted_value)
